{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of creating and operating distributions in Pixyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3b92e22af0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.distributions import Normal\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 20\n",
    "y_dim = 30\n",
    "z_dim = 40\n",
    "a_dim = 50\n",
    "batch_n = 2\n",
    "\n",
    "class P1(Normal):\n",
    "    def __init__(self):\n",
    "        super(P1, self).__init__(cond_var=[\"y\", \"a\"], var=[\"x\"], name=\"p_{1}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(y_dim, 10)\n",
    "        self.fc2 = nn.Linear(a_dim, 10)\n",
    "        self.fc21 = nn.Linear(10+10, 20)\n",
    "        self.fc22 = nn.Linear(10+10, 20)\n",
    "\n",
    "    def forward(self, a, y):\n",
    "        h1 = F.relu(self.fc1(y))\n",
    "        h2 = F.relu(self.fc2(a))\n",
    "        h12 = torch.cat([h1, h2], 1)\n",
    "        return {\"loc\": self.fc21(h12), \"scale\": F.softplus(self.fc22(h12))}\n",
    "\n",
    "class P2(Normal):\n",
    "    def __init__(self):\n",
    "        super(P2, self).__init__(cond_var=[\"x\", \"y\"], var=[\"z\"], name=\"p_{2}\")\n",
    "\n",
    "        self.fc3 = nn.Linear(x_dim, 30)\n",
    "        self.fc4 = nn.Linear(30+y_dim, 400)\n",
    "        self.fc51 = nn.Linear(400, 20)\n",
    "        self.fc52 = nn.Linear(400, 20)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h3 = F.relu(self.fc3(x))\n",
    "        h4 = F.relu(self.fc4(torch.cat([h3, y], 1)))\n",
    "        return {\"loc\": self.fc51(h4), \"scale\": F.softplus(self.fc52(h4))}\n",
    "    \n",
    "p4 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"a\"], features_shape=[a_dim], name=\"p_{4}\")\n",
    "p6 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"y\"], features_shape=[y_dim], name=\"p_{6}\")\n",
    "    \n",
    "x = torch.from_numpy(np.random.random((batch_n, x_dim)).astype(\"float32\"))\n",
    "y = torch.from_numpy(np.random.random((batch_n, y_dim)).astype(\"float32\"))\n",
    "a = torch.from_numpy(np.random.random((batch_n, a_dim)).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = P1()\n",
    "p2 = P2()\n",
    "p3 = p2 * p1\n",
    "p3.name = \"p_{3}\"\n",
    "p5 = p3 * p4\n",
    "p5.name = \"p_{5}\"\n",
    "p_all = p1*p2*p4*p6\n",
    "p_all.name = \"p_{all}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1)\n",
    "print_latex(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z|x,y)\n",
      "Network architecture:\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{2}(z|x,y)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2)\n",
    "print_latex(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{3}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{3}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3)\n",
    "print_latex(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{4}(a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p4)\n",
    "print_latex(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{5}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{5}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p5)\n",
    "print_latex(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{all}(z,x,a,y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{6}, distribution_name=Normal,\n",
      "    var=['y'], cond_var=[], input_var=[], features_shape=torch.Size([30])\n",
      "    (loc): torch.Size([1, 30])\n",
      "    (scale): torch.Size([1, 30])\n",
      "  )\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{all}(z,x,a,y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_all)\n",
    "print_latex(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([10, 30])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([10, 50])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([30, 20])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([400, 60])\n",
      "<class 'torch.Tensor'> torch.Size([400])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for param in p3.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-1.1080, -1.1448,  0.3645,  0.8265, -0.0342,  0.3246,  1.2158, -0.7814,\n",
       "           0.4136,  0.1797, -0.7113, -0.6147,  0.6630, -1.2774, -1.8449, -0.8617,\n",
       "           0.6214,  0.2736,  0.2798, -0.0211],\n",
       "         [-0.2552, -0.6734, -0.0462,  2.1422,  0.8061,  0.6504, -0.9144,  0.3330,\n",
       "          -0.6654,  1.8404,  0.4712, -0.1908, -0.6778,  0.7943,  0.8817,  1.1594,\n",
       "           0.3425, -0.7468,  0.2854,  0.3387]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[ 0.2361,  0.4032,  0.0695, -0.5533,  1.4330, -1.2905,  0.9687,\n",
       "           -0.0577,  1.1533, -0.5694,  1.0572,  0.6492, -0.0456, -0.4337,\n",
       "            1.4848,  0.2504,  1.4454, -0.7443,  0.8191, -0.9356],\n",
       "          [ 2.2134,  0.0875, -0.4107,  0.4107,  0.4590,  0.9196,  0.5432,\n",
       "           -0.6694,  0.1509, -0.9104, -0.0669,  0.9513,  0.9181, -0.3561,\n",
       "            1.1535, -1.4426,  1.5048, -1.1466, -0.4321,  0.4410]],\n",
       " \n",
       "         [[ 0.4027,  0.5023,  1.1012,  0.0531, -0.0900,  0.3504,  0.0224,\n",
       "           -1.0426,  0.4490, -0.7878, -0.0834,  0.2744,  0.5666, -0.6071,\n",
       "            0.5528,  0.6068,  2.3289, -0.1833,  1.1016,  0.2819],\n",
       "          [-0.3916, -1.8881,  1.1777,  0.1526,  0.3053,  0.1854,  0.4316,\n",
       "           -1.7862,  0.2638,  0.0908, -0.7300,  0.1897, -1.0572, -0.4123,\n",
       "            0.6058,  1.0998, -1.3688,  0.2041,  0.6267,  0.4025]],\n",
       " \n",
       "         [[-0.3304,  0.0434,  0.6254, -0.2385,  0.0669, -1.3313,  0.1627,\n",
       "            1.0354,  1.1990,  0.9442, -0.4519,  1.3349, -0.2151,  0.0939,\n",
       "            0.3089,  0.3815, -1.2210, -0.0036,  0.5957, -0.3361],\n",
       "          [-1.5332, -0.1496, -0.9899,  0.0919,  0.2504,  0.7608,  0.4223,\n",
       "           -1.0838,  0.1169,  0.4425, -0.2116, -0.6260, -1.2876,  0.3907,\n",
       "           -1.0604,  0.7637,  0.8872, -0.5940, -0.0561, -1.3081]],\n",
       " \n",
       "         [[-0.2493, -0.0311, -0.6442,  0.5174,  0.8542,  1.0385,  0.2219,\n",
       "           -0.9068,  0.4168,  1.9617,  0.3100,  0.4736,  0.1256, -0.0876,\n",
       "           -0.0916, -0.6465,  0.7216,  0.1871,  0.6541,  0.5392],\n",
       "          [-1.0218, -0.1965,  0.0706, -0.2952,  0.5918, -1.6576, -0.4101,\n",
       "           -0.3073,  0.9434, -0.8761,  0.5883,  0.6883, -0.2612,  0.2325,\n",
       "            1.3303, -0.5172,  0.1138,  0.0692,  0.8437,  0.7237]],\n",
       " \n",
       "         [[-0.2033, -0.5700, -0.8066,  0.4887,  0.1215,  0.7008,  0.0296,\n",
       "            0.0981, -0.3124, -1.4769, -1.1245,  0.9173, -0.7775, -0.7422,\n",
       "            1.1199,  0.3385, -0.2676, -1.4024, -0.2347, -0.3692],\n",
       "          [ 0.9237, -0.2236,  0.8834, -0.4157,  0.4553,  0.2666, -0.0231,\n",
       "           -1.2615,  0.7737,  0.0157, -0.3860,  0.4731, -0.6920, -1.2925,\n",
       "           -1.1999,  1.2535,  1.7377, -0.6033,  0.2381, -0.3432]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, sample_shape=[5], return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([[0.1320, 0.0491, 0.7590, 0.5842, 0.3375, 0.9551, 0.8056, 0.2712, 0.9071,\n",
       "          0.5097, 0.0261, 0.8238, 0.0823, 0.6461, 0.4548, 0.2272, 0.6942, 0.6650,\n",
       "          0.5703, 0.9859, 0.6487, 0.8432, 0.5360, 0.2182, 0.4599, 0.0878, 0.4800,\n",
       "          0.6572, 0.4341, 0.8360, 0.2246, 0.3745, 0.1591, 0.8631, 0.6649, 0.9799,\n",
       "          0.5513, 0.3578, 0.1858, 0.3634, 0.8616, 0.1546, 0.3706, 0.5987, 0.9042,\n",
       "          0.0458, 0.6299, 0.5196, 0.9889, 0.2224],\n",
       "         [0.3299, 0.7013, 0.2179, 0.1459, 0.1066, 0.8810, 0.7327, 0.2921, 0.3975,\n",
       "          0.3387, 0.7939, 0.2516, 0.2301, 0.2209, 0.8894, 0.1208, 0.5188, 0.4123,\n",
       "          0.5215, 0.7918, 0.9131, 0.5561, 0.5978, 0.3926, 0.9542, 0.3080, 0.0552,\n",
       "          0.7052, 0.2928, 0.5813, 0.5792, 0.9748, 0.1479, 0.6273, 0.0294, 0.7211,\n",
       "          0.7053, 0.6399, 0.3759, 0.6624, 0.8164, 0.8344, 0.3406, 0.6040, 0.2594,\n",
       "          0.5917, 0.5722, 0.7041, 0.2925, 0.1478]]),\n",
       " 'y': tensor([[0.5370, 0.9887, 0.4120, 0.4911, 0.6232, 0.3370, 0.7106, 0.6299, 0.5968,\n",
       "          0.6134, 0.2168, 0.6809, 0.6891, 0.6831, 0.1974, 0.1279, 0.3578, 0.0317,\n",
       "          0.5218, 0.0989, 0.5027, 0.9794, 0.6124, 0.7499, 0.0116, 0.1185, 0.5691,\n",
       "          0.7956, 0.5116, 0.0600],\n",
       "         [0.6602, 0.8747, 0.5161, 0.3215, 0.6065, 0.4116, 0.3064, 0.7506, 0.1647,\n",
       "          0.5874, 0.4610, 0.4767, 0.7404, 0.3111, 0.4335, 0.8460, 0.1291, 0.8882,\n",
       "          0.8390, 0.8023, 0.4412, 0.6205, 0.4831, 0.3605, 0.8874, 0.6466, 0.2698,\n",
       "          0.2137, 0.8227, 0.6566]]),\n",
       " 'x': tensor([[ 1.4048, -0.5234, -1.2810,  1.2784,  0.4776, -0.0566,  1.1488, -1.0563,\n",
       "           0.2049,  1.4435, -0.3483,  0.8220,  0.4209, -1.2539,  0.0700,  0.2974,\n",
       "          -0.1061,  1.1770, -0.6415,  0.4766],\n",
       "         [ 1.1014,  0.2645,  1.0874, -0.5584,  0.6042,  0.1999, -0.0127,  0.1131,\n",
       "           0.1090, -0.7641, -1.0372,  1.0218,  0.0677, -1.0491, -0.9952, -1.1081,\n",
       "          -0.2088, -0.1853,  1.9301, -0.6712]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\log p_{1}(x|y,a)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\log p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_log_prob = p1.log_prob()\n",
    "print(p1_log_prob)\n",
    "print_latex(p1_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-25.0060, -26.2503], grad_fn=<SumBackward2>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(p1_log_prob.eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.9541, -24.4006], grad_fn=<SumBackward2>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p2.sample({\"x\":x, \"y\":y})\n",
    "print(p2.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': tensor([[0.5370, 0.9887, 0.4120, 0.4911, 0.6232, 0.3370, 0.7106, 0.6299, 0.5968,\n",
      "         0.6134, 0.2168, 0.6809, 0.6891, 0.6831, 0.1974, 0.1279, 0.3578, 0.0317,\n",
      "         0.5218, 0.0989, 0.5027, 0.9794, 0.6124, 0.7499, 0.0116, 0.1185, 0.5691,\n",
      "         0.7956, 0.5116, 0.0600],\n",
      "        [0.6602, 0.8747, 0.5161, 0.3215, 0.6065, 0.4116, 0.3064, 0.7506, 0.1647,\n",
      "         0.5874, 0.4610, 0.4767, 0.7404, 0.3111, 0.4335, 0.8460, 0.1291, 0.8882,\n",
      "         0.8390, 0.8023, 0.4412, 0.6205, 0.4831, 0.3605, 0.8874, 0.6466, 0.2698,\n",
      "         0.2137, 0.8227, 0.6566]]), 'a': tensor([[0.1320, 0.0491, 0.7590, 0.5842, 0.3375, 0.9551, 0.8056, 0.2712, 0.9071,\n",
      "         0.5097, 0.0261, 0.8238, 0.0823, 0.6461, 0.4548, 0.2272, 0.6942, 0.6650,\n",
      "         0.5703, 0.9859, 0.6487, 0.8432, 0.5360, 0.2182, 0.4599, 0.0878, 0.4800,\n",
      "         0.6572, 0.4341, 0.8360, 0.2246, 0.3745, 0.1591, 0.8631, 0.6649, 0.9799,\n",
      "         0.5513, 0.3578, 0.1858, 0.3634, 0.8616, 0.1546, 0.3706, 0.5987, 0.9042,\n",
      "         0.0458, 0.6299, 0.5196, 0.9889, 0.2224],\n",
      "        [0.3299, 0.7013, 0.2179, 0.1459, 0.1066, 0.8810, 0.7327, 0.2921, 0.3975,\n",
      "         0.3387, 0.7939, 0.2516, 0.2301, 0.2209, 0.8894, 0.1208, 0.5188, 0.4123,\n",
      "         0.5215, 0.7918, 0.9131, 0.5561, 0.5978, 0.3926, 0.9542, 0.3080, 0.0552,\n",
      "         0.7052, 0.2928, 0.5813, 0.5792, 0.9748, 0.1479, 0.6273, 0.0294, 0.7211,\n",
      "         0.7053, 0.6399, 0.3759, 0.6624, 0.8164, 0.8344, 0.3406, 0.6040, 0.2594,\n",
      "         0.5917, 0.5722, 0.7041, 0.2925, 0.1478]]), 'x': tensor([[ 2.9214e-01,  3.0502e-01, -1.6323e+00, -4.2545e-01,  5.2582e-01,\n",
      "          1.2860e-01, -2.8179e-01, -5.2124e-01,  1.6933e+00,  8.0095e-01,\n",
      "          1.2295e-01, -4.3552e-01,  1.4594e-02, -8.9916e-01,  1.6161e+00,\n",
      "         -4.7363e-01, -3.9393e-01, -3.1160e-01, -1.4073e-03,  2.2941e-02],\n",
      "        [-4.2936e-01,  4.3033e-01, -1.6451e-01,  1.1551e+00,  1.1334e+00,\n",
      "          1.2930e-01,  6.0578e-03,  1.4455e-01,  1.2811e+00,  8.3445e-01,\n",
      "         -7.4632e-01,  4.1323e-01, -1.6250e-01, -7.6073e-01,  2.7104e-01,\n",
      "         -3.0877e-01, -5.8979e-01, -1.4003e-01,  2.9895e-01, -5.2059e-01]])}\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': tensor([[0.5370, 0.9887, 0.4120, 0.4911, 0.6232, 0.3370, 0.7106, 0.6299, 0.5968,\n",
       "          0.6134, 0.2168, 0.6809, 0.6891, 0.6831, 0.1974, 0.1279, 0.3578, 0.0317,\n",
       "          0.5218, 0.0989, 0.5027, 0.9794, 0.6124, 0.7499, 0.0116, 0.1185, 0.5691,\n",
       "          0.7956, 0.5116, 0.0600],\n",
       "         [0.6602, 0.8747, 0.5161, 0.3215, 0.6065, 0.4116, 0.3064, 0.7506, 0.1647,\n",
       "          0.5874, 0.4610, 0.4767, 0.7404, 0.3111, 0.4335, 0.8460, 0.1291, 0.8882,\n",
       "          0.8390, 0.8023, 0.4412, 0.6205, 0.4831, 0.3605, 0.8874, 0.6466, 0.2698,\n",
       "          0.2137, 0.8227, 0.6566]]),\n",
       " 'a': tensor([[0.1320, 0.0491, 0.7590, 0.5842, 0.3375, 0.9551, 0.8056, 0.2712, 0.9071,\n",
       "          0.5097, 0.0261, 0.8238, 0.0823, 0.6461, 0.4548, 0.2272, 0.6942, 0.6650,\n",
       "          0.5703, 0.9859, 0.6487, 0.8432, 0.5360, 0.2182, 0.4599, 0.0878, 0.4800,\n",
       "          0.6572, 0.4341, 0.8360, 0.2246, 0.3745, 0.1591, 0.8631, 0.6649, 0.9799,\n",
       "          0.5513, 0.3578, 0.1858, 0.3634, 0.8616, 0.1546, 0.3706, 0.5987, 0.9042,\n",
       "          0.0458, 0.6299, 0.5196, 0.9889, 0.2224],\n",
       "         [0.3299, 0.7013, 0.2179, 0.1459, 0.1066, 0.8810, 0.7327, 0.2921, 0.3975,\n",
       "          0.3387, 0.7939, 0.2516, 0.2301, 0.2209, 0.8894, 0.1208, 0.5188, 0.4123,\n",
       "          0.5215, 0.7918, 0.9131, 0.5561, 0.5978, 0.3926, 0.9542, 0.3080, 0.0552,\n",
       "          0.7052, 0.2928, 0.5813, 0.5792, 0.9748, 0.1479, 0.6273, 0.0294, 0.7211,\n",
       "          0.7053, 0.6399, 0.3759, 0.6624, 0.8164, 0.8344, 0.3406, 0.6040, 0.2594,\n",
       "          0.5917, 0.5722, 0.7041, 0.2925, 0.1478]]),\n",
       " 'x': tensor([[ 2.9214e-01,  3.0502e-01, -1.6323e+00, -4.2545e-01,  5.2582e-01,\n",
       "           1.2860e-01, -2.8179e-01, -5.2124e-01,  1.6933e+00,  8.0095e-01,\n",
       "           1.2295e-01, -4.3552e-01,  1.4594e-02, -8.9916e-01,  1.6161e+00,\n",
       "          -4.7363e-01, -3.9393e-01, -3.1160e-01, -1.4073e-03,  2.2941e-02],\n",
       "         [-4.2936e-01,  4.3033e-01, -1.6451e-01,  1.1551e+00,  1.1334e+00,\n",
       "           1.2930e-01,  6.0578e-03,  1.4455e-01,  1.2811e+00,  8.3445e-01,\n",
       "          -7.4632e-01,  4.1323e-01, -1.6250e-01, -7.6073e-01,  2.7104e-01,\n",
       "          -3.0877e-01, -5.8979e-01, -1.4003e-01,  2.9895e-01, -5.2059e-01]]),\n",
       " 'z': tensor([[-0.3390,  0.0152, -1.6700,  0.2281,  0.4263,  0.1865, -0.3905,  0.7898,\n",
       "           0.4050, -0.9966,  0.1397,  0.1434,  0.6708, -1.5776,  0.0937,  0.0294,\n",
       "          -0.1761, -0.5607, -0.9517,  0.2629],\n",
       "         [ 1.3312,  0.0823,  0.5742,  0.7110, -0.6437, -0.2455,  0.8424,  0.2291,\n",
       "          -0.2059, -0.2799,  0.7530,  1.6192,  0.3000,  0.5020,  1.2179,  1.2535,\n",
       "           0.8864,  1.9246, -0.2076,  0.1590]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.sample(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-40.2794, -35.0491], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p3.sample({\"y\":y, \"a\":a}, batch_n=batch_n)\n",
    "print(p3.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-155.2850, -152.5049], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p_all.sample(batch_n=batch_n)\n",
    "print(p_all.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
